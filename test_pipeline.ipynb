{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import *\n",
    "\n",
    "from src.data.preprocessing import preprocess, features_input\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from typing import Dict, Union, Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.transformer_enc import EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurtestard/envs/ntnu/aitask3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = EncoderModel()\n",
    "\n",
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save(MODEL_FOLDER.joinpath(\"test.pt\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ais_train = pd.read_csv(AIS_TRAIN, sep='|')\n",
    "ais_train['time'] = pd.to_datetime(ais_train['time'])\n",
    "\n",
    "ais_test = pd.read_csv(AIS_TEST, sep=\",\")\n",
    "ais_test['time'] = pd.to_datetime(ais_test['time']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 48\n",
    "do_preprocess = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(seq_len = 48, do_preprocess = True):\n",
    "    if do_preprocess:\n",
    "        ais_train = pd.read_csv(AIS_TRAIN, sep='|')\n",
    "        ais_train['time'] = pd.to_datetime(ais_train['time'])\n",
    "\n",
    "        ais_test = pd.read_csv(AIS_TEST, sep=\",\")\n",
    "        ais_test['time'] = pd.to_datetime(ais_test['time']) \n",
    "\n",
    "        X_train, X_val, y_train, y_val, test_set, scaler, dropped_vessel_ids = preprocess(\n",
    "            ais_train, \n",
    "            ais_test,\n",
    "            seq_type=\"n_in_1_out\",\n",
    "            seq_len=seq_len,\n",
    "            seq_len_out=1,\n",
    "            verbose=True,\n",
    "            to_torch=True,\n",
    "            parallelize_seq = True,\n",
    "            scaler=MinMaxScaler()\n",
    "        )\n",
    "\n",
    "        X_train = torch.Tensor(X_train)\n",
    "        y_train = torch.Tensor(y_train)\n",
    "\n",
    "        X_val = torch.Tensor(X_val)\n",
    "        y_val = torch.Tensor(y_val)\n",
    "\n",
    "        torch.save(X_train, LAST_PREPROCESS_FOLDER.joinpath(\"X_train.pt\"))\n",
    "        torch.save(y_train, LAST_PREPROCESS_FOLDER.joinpath(\"y_train.pt\"))\n",
    "        torch.save(X_val, LAST_PREPROCESS_FOLDER.joinpath(\"X_val.pt\"))\n",
    "        torch.save(y_val, LAST_PREPROCESS_FOLDER.joinpath(\"y_val.pt\"))\n",
    "\n",
    "        joblib.dump(scaler, LAST_PREPROCESS_FOLDER.joinpath(\"scaler\")) \n",
    "        test_set.to_csv(LAST_PREPROCESS_FOLDER.joinpath(\"test_set.csv\"))\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            \n",
    "            X_train = torch.load(LAST_PREPROCESS_FOLDER.joinpath(\"X_train.pt\"), weights_only=True)\n",
    "            y_train = torch.load(LAST_PREPROCESS_FOLDER.joinpath(\"y_train.pt\"), weights_only=True)\n",
    "            X_val = torch.load(LAST_PREPROCESS_FOLDER.joinpath(\"X_val.pt\"), weights_only=True)\n",
    "            y_val = torch.load(LAST_PREPROCESS_FOLDER.joinpath(\"y_val.pt\"), weights_only=True)\n",
    "\n",
    "            scaler = joblib.load(LAST_PREPROCESS_FOLDER.joinpath(\"scaler\")) \n",
    "            test_set = pd.read_csv(LAST_PREPROCESS_FOLDER.joinpath(\"test_set.csv\"))\n",
    "            \n",
    "            dropped_vessel_ids = ['61e9f3adb937134a3c4bfe37', '61e9f3cbb937134a3c4bff09']\n",
    "\n",
    "        except:\n",
    "            print(f\"ERROR: File missing in {str(LAST_PREPROCESS_FOLDER)}. Now run preprocessing...\")\n",
    "            return pipeline(seq_len=seq_len, do_preprocess=True, paralize_preprocess=True)\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val, test_set, scaler, dropped_vessel_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, test_set, scaler, dropped_vessel_ids = pipeline(seq_len, do_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131115</th>\n",
       "      <td>2024-01-12 14:07:47</td>\n",
       "      <td>308.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-6</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>01-08 06:00</td>\n",
       "      <td>7.50361</td>\n",
       "      <td>77.58340</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>61d376b393c6feb83e5eb50c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131279</th>\n",
       "      <td>2024-01-12 14:31:00</td>\n",
       "      <td>307.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>5</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>01-14 23:30</td>\n",
       "      <td>7.57302</td>\n",
       "      <td>77.49505</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>61d376d893c6feb83e5eb546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131514</th>\n",
       "      <td>2024-01-12 14:57:23</td>\n",
       "      <td>306.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>01-14 23:30</td>\n",
       "      <td>7.65043</td>\n",
       "      <td>77.39404</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>61d376d893c6feb83e5eb546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131696</th>\n",
       "      <td>2024-01-12 15:18:48</td>\n",
       "      <td>307.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>01-14 23:30</td>\n",
       "      <td>7.71275</td>\n",
       "      <td>77.31394</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>61d376d893c6feb83e5eb546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131885</th>\n",
       "      <td>2024-01-12 15:39:47</td>\n",
       "      <td>307.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>7</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>01-14 23:30</td>\n",
       "      <td>7.77191</td>\n",
       "      <td>77.23585</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>61d376d893c6feb83e5eb546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521244</th>\n",
       "      <td>2024-05-07 22:36:16</td>\n",
       "      <td>324.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-2</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 03:00</td>\n",
       "      <td>59.63337</td>\n",
       "      <td>21.43237</td>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>61d373b83aeaecc07011a62b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521409</th>\n",
       "      <td>2024-05-07 22:57:05</td>\n",
       "      <td>324.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-3</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 03:00</td>\n",
       "      <td>59.69588</td>\n",
       "      <td>21.34225</td>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>61d373b83aeaecc07011a62b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521625</th>\n",
       "      <td>2024-05-07 23:17:54</td>\n",
       "      <td>356.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-1</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 03:00</td>\n",
       "      <td>59.76388</td>\n",
       "      <td>21.35317</td>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>61d373b83aeaecc07011a62b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521821</th>\n",
       "      <td>2024-05-07 23:38:13</td>\n",
       "      <td>52.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 03:00</td>\n",
       "      <td>59.83316</td>\n",
       "      <td>21.38489</td>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>61d373b83aeaecc07011a62b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522014</th>\n",
       "      <td>2024-05-07 23:59:01</td>\n",
       "      <td>53.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 03:00</td>\n",
       "      <td>59.89167</td>\n",
       "      <td>21.54685</td>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>61d373b83aeaecc07011a62b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522033 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "131115  2024-01-12 14:07:47  308.1  17.1   -6      316        0  01-08 06:00   \n",
       "131279  2024-01-12 14:31:00  307.6  17.3    5      313        0  01-14 23:30   \n",
       "131514  2024-01-12 14:57:23  306.8  16.9    5      312        0  01-14 23:30   \n",
       "131696  2024-01-12 15:18:48  307.9  16.9    6      313        0  01-14 23:30   \n",
       "131885  2024-01-12 15:39:47  307.0  16.3    7      313        0  01-14 23:30   \n",
       "...                     ...    ...   ...  ...      ...      ...          ...   \n",
       "1521244 2024-05-07 22:36:16  324.1  13.5   -2      325        0  05-08 03:00   \n",
       "1521409 2024-05-07 22:57:05  324.2  13.3   -3      326        0  05-08 03:00   \n",
       "1521625 2024-05-07 23:17:54  356.5  12.2   -1      354        0  05-08 03:00   \n",
       "1521821 2024-05-07 23:38:13   52.6  17.3    3       50        0  05-08 03:00   \n",
       "1522014 2024-05-07 23:59:01   53.6  17.7   -1       51        0  05-08 03:00   \n",
       "\n",
       "         latitude  longitude                   vesselId  \\\n",
       "131115    7.50361   77.58340   61e9f38eb937134a3c4bfd8b   \n",
       "131279    7.57302   77.49505   61e9f38eb937134a3c4bfd8b   \n",
       "131514    7.65043   77.39404   61e9f38eb937134a3c4bfd8b   \n",
       "131696    7.71275   77.31394   61e9f38eb937134a3c4bfd8b   \n",
       "131885    7.77191   77.23585   61e9f38eb937134a3c4bfd8b   \n",
       "...           ...        ...                        ...   \n",
       "1521244  59.63337   21.43237  clh6aqawa0007gh0z9h6zi9bo   \n",
       "1521409  59.69588   21.34225  clh6aqawa0007gh0z9h6zi9bo   \n",
       "1521625  59.76388   21.35317  clh6aqawa0007gh0z9h6zi9bo   \n",
       "1521821  59.83316   21.38489  clh6aqawa0007gh0z9h6zi9bo   \n",
       "1522014  59.89167   21.54685  clh6aqawa0007gh0z9h6zi9bo   \n",
       "\n",
       "                           portId  \n",
       "131115   61d376b393c6feb83e5eb50c  \n",
       "131279   61d376d893c6feb83e5eb546  \n",
       "131514   61d376d893c6feb83e5eb546  \n",
       "131696   61d376d893c6feb83e5eb546  \n",
       "131885   61d376d893c6feb83e5eb546  \n",
       "...                           ...  \n",
       "1521244  61d373b83aeaecc07011a62b  \n",
       "1521409  61d373b83aeaecc07011a62b  \n",
       "1521625  61d373b83aeaecc07011a62b  \n",
       "1521821  61d373b83aeaecc07011a62b  \n",
       "1522014  61d373b83aeaecc07011a62b  \n",
       "\n",
       "[1522033 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_val = ais_train.copy()[ais_train[\"vesselId\"] not in dropped_vessel_ids].sort_values([\"vesselId\",\"time\"])\n",
    "df_val = ais_train.copy()[~ais_train[\"vesselId\"].isin(dropped_vessel_ids)].sort_values([\"vesselId\", \"time\"])\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "v_min = np.inf\n",
    "v_id = \"\"\n",
    "for vessel_id in list(ais_test[\"vesselId\"].unique()):\n",
    "    if len(ais_train[ais_train[\"vesselId\"]==vessel_id]) < v_min:\n",
    "        v_id = vessel_id\n",
    "        v_min = len(ais_train[ais_train[\"vesselId\"]==vessel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "v_max = -np.inf\n",
    "v_id = \"\"\n",
    "for vessel_id in list(ais_test[\"vesselId\"].unique()):\n",
    "    if len(ais_test[ais_test[\"vesselId\"]==vessel_id]) > v_max:\n",
    "        v_id = vessel_id\n",
    "        v_max = len(ais_test[ais_test[\"vesselId\"]==vessel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(100, 48, 6).mean(dim=1).reshape(100,1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vesselId</th>\n",
       "      <th>time</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131115</th>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>2024-01-12 14:07:47</td>\n",
       "      <td>1393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131279</th>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>2024-01-12 14:31:00</td>\n",
       "      <td>1583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131514</th>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>2024-01-12 14:57:23</td>\n",
       "      <td>1285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131696</th>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>2024-01-12 15:18:48</td>\n",
       "      <td>1259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131885</th>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>2024-01-12 15:39:47</td>\n",
       "      <td>901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521244</th>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>2024-05-07 22:36:16</td>\n",
       "      <td>1249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521409</th>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>2024-05-07 22:57:05</td>\n",
       "      <td>1249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521625</th>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>2024-05-07 23:17:54</td>\n",
       "      <td>1219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521821</th>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>2024-05-07 23:38:13</td>\n",
       "      <td>1248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522014</th>\n",
       "      <td>clh6aqawa0007gh0z9h6zi9bo</td>\n",
       "      <td>2024-05-07 23:59:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          vesselId                time  time_diff\n",
       "131115    61e9f38eb937134a3c4bfd8b 2024-01-12 14:07:47     1393.0\n",
       "131279    61e9f38eb937134a3c4bfd8b 2024-01-12 14:31:00     1583.0\n",
       "131514    61e9f38eb937134a3c4bfd8b 2024-01-12 14:57:23     1285.0\n",
       "131696    61e9f38eb937134a3c4bfd8b 2024-01-12 15:18:48     1259.0\n",
       "131885    61e9f38eb937134a3c4bfd8b 2024-01-12 15:39:47      901.0\n",
       "...                            ...                 ...        ...\n",
       "1521244  clh6aqawa0007gh0z9h6zi9bo 2024-05-07 22:36:16     1249.0\n",
       "1521409  clh6aqawa0007gh0z9h6zi9bo 2024-05-07 22:57:05     1249.0\n",
       "1521625  clh6aqawa0007gh0z9h6zi9bo 2024-05-07 23:17:54     1219.0\n",
       "1521821  clh6aqawa0007gh0z9h6zi9bo 2024-05-07 23:38:13     1248.0\n",
       "1522014  clh6aqawa0007gh0z9h6zi9bo 2024-05-07 23:59:01        NaN\n",
       "\n",
       "[1522065 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.features import create_time_diff_feature\n",
    "\n",
    "ais_tr_dev = create_time_diff_feature(ais_train)\n",
    "ais_tr_dev.sort_values([\"vesselId\", \"time\"])[[\"vesselId\", \"time\", \"time_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39 * 60 + 47 - (18 * 60 + 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455491"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[0] + X_val.shape[0]) - (len(ais_train[\"vesselId\"].unique()) - 2) * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_vessel_ids = ['61e9f3adb937134a3c4bfe37', '61e9f3cbb937134a3c4bff09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ais_train[ais_train[\"vesselId\"]==\"61e9f3adb937134a3c4bfe37\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def make_df_val(\n",
    "        train_set: pd.DataFrame,\n",
    "        dropped_vessel_ids: List[str],        \n",
    "        idx: int,\n",
    "\n",
    "    ) -> pd.DataFrame:\n",
    "    df_val = train_set.copy()[train_set[\"vessel_id\"] not in dropped_vessel_ids].sort_values(\"time\")\n",
    "    train_set.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = train_set.copy()[train_set[\"vessel_id\"] not in dropped_vessel_ids].sort_values(\"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ffn = 126\n",
    "d_model = 32\n",
    "activation_dec: Union[str | Callable[[torch.Tensor], torch.Tensor]] = nn.SiLU()\n",
    "\n",
    "transformer_decoder_params = {\n",
    "    \"d_model\": d_model,\n",
    "    \"nhead\": 8,\n",
    "    # \"num_encoder_layers\": 6,\n",
    "    # \"num_decoder_layers\": 2,\n",
    "    \"dim_feedforward\": dim_ffn,\n",
    "    \"dropout\": 0.1,\n",
    "    \"activation\": activation_dec,\n",
    "    \"layer_norm_eps\": 0.00001,\n",
    "    \"batch_first\": True,\n",
    "    \"norm_first\": False,\n",
    "    # \"bias\": True,\n",
    "    \"device\": DEVICE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            decoder_params: Dict[int,Union[int, float, bool]] = transformer_decoder_params, \n",
    "            num_features: int = 7, \n",
    "            num_outputs: int = 6, \n",
    "            num_layers: int = 1,\n",
    "            act_out: nn.Module | None = None\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Linear(num_features, d_model)\n",
    "        dec_layer = nn.TransformerDecoderLayer(**decoder_params)\n",
    "        self.model = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "        self.ffn = nn.Linear(d_model, num_outputs)\n",
    "        self.act_out = act_out # nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        len_b, len_s, _ = x.shape\n",
    "        emb = self.emb_layer(x)\n",
    "        out = self.model(emb, emb)\n",
    "        out = out[:, -1, :].view(len_b, 1, -1)\n",
    "        \n",
    "        if self.act_out:\n",
    "            return self.act_out(self.ffn(out))\n",
    "        return self.ffn(out)\n",
    "\n",
    "\n",
    "model = DecoderModel(act_out=nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.trainer import Trainer\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss=nn.MSELoss(),\n",
    "    optimizer=torch.optim.AdamW(params=model.parameters()),\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train).to(DEVICE)\n",
    "y_train = torch.Tensor(y_train).to(DEVICE)\n",
    "\n",
    "X_val = torch.Tensor(X_val).to(DEVICE)\n",
    "y_val = torch.Tensor(y_val).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    # X_val=X_val,\n",
    "    # y_val=y_val,\n",
    "    epochs=1,\n",
    "    eval_on_test=True,\n",
    "    k_folds=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = trainer.eval(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    print(\"Score on validation set (rmse):\", np.sqrt(score))\n",
    "except:\n",
    "    print(\"Score on validation set (rmse):\", np.sqrt(score.cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_forecast(seq, model, steps, sequence_length):\n",
    "    predicted = []\n",
    "    current_sequence = seq[:sequence_length].reshape(1,sequence_length,7)\n",
    "    # current_sequence = last_known[-sequence_length:]\n",
    "    for k in range(steps):\n",
    "        # next_pred = model.predict(current_sequence.reshape(1, sequence_length, -1))[0]\n",
    "        x_test = torch.Tensor(current_sequence).to(DEVICE)\n",
    "        y_pred = model.predict(x_test)[0,0,:]\n",
    "\n",
    "        predicted.append(y_pred)\n",
    "        seq[seq_len+k] = np.array([seq[k+1][0], *y_pred])\n",
    "        \n",
    "        current_sequence = seq[k+1:k+1+seq_len].reshape(1,seq_len,7)\n",
    "    print(np.array(predicted).shape)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION STEP\n",
    "\n",
    "grouped_test = test_set.groupby(\"vesselId\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "sequence_length = seq_len\n",
    "\n",
    "for vessel_id, group in tqdm(grouped_test, colour=\"green\"):\n",
    "    forecast_steps = len(group['time'].values) - seq_len\n",
    "\n",
    "    last_known_features = group[features_input].values\n",
    "\n",
    "    future_preds = iterative_forecast(last_known_features, trainer, forecast_steps, sequence_length)\n",
    "    \n",
    "    group.loc[group.index[seq_len:],['cog', 'sog', 'rot', 'heading', 'latitude', 'longitude']] = future_preds\n",
    "    \n",
    "    group[features_input] = scaler.inverse_transform(group[features_input])\n",
    "    predictions.append(group.copy())\n",
    "\n",
    "df_preds = pd.concat(predictions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_preds[[\"ID\",\"longitude\",\"latitude\"]].sort_values(\"ID\")[:51739]\n",
    "res = res.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMIT RESULT\n",
    "import uuid\n",
    "# res = pd.merge(ais_test, df_preds[[\"vesselId\",\"time\", \"latitude\", \"longitude\"]],on=[\"time\", \"vesselId\"], how=\"left\")\n",
    "res[\"longitude_predicted\"] = res[\"longitude\"]\n",
    "res[\"latitude_predicted\"] = res[\"latitude\"]\n",
    "# res = df_preds[[\"ID\"]]\n",
    "# res[\"id\"] = res[\"ID\"]\n",
    "res = res.drop(columns=[\"longitude\", \"latitude\"])\n",
    "\n",
    "def make_file_name() -> str:\n",
    "    file_name = str(uuid.uuid4()) + \".csv\"\n",
    "    print(f\"Submission file name is: {file_name}\")\n",
    "    return file_name\n",
    "\n",
    "def submit(forecast: pd.DataFrame, file_name: str = None) -> None:\n",
    "    sample_submission = pd.read_csv(AIS_SAMPLE_SUBMISSION)\n",
    "    file_name = file_name if file_name else make_file_name()\n",
    "\n",
    "    repertory = SUBMISSION_FODLER.joinpath(file_name)\n",
    "    sample_submission = sample_submission[['ID']].merge(forecast[[\"ID\",\"longitude_predicted\",\"latitude_predicted\"]], on='ID', how='left')\n",
    "    try:\n",
    "        sample_submission.to_csv(repertory, index=False)\n",
    "    except:\n",
    "        print(\"Error register file\")\n",
    "        submit(forecast)\n",
    "\n",
    "submit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitask3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
